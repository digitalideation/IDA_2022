## Data Self Portrait – The Quantified Self

### Tagesaufgabe
Erarbeite eine Darstellung mit p5.js, bei der dein Gesicht in irgendeiner Form eine Rolle spielt. 

**_Inspiration_**
* http://www.generative-gestaltung.de/2/
* https://tinyurl.com/bdz437y4  Alex Dragulescu, lexigraphs
* https://medium.com/swlh/new-designs-for-living-online-ffb541711757
* https://github.com/shiffman/Face-It
* https://rachelbinx.com/project/wifidiary


***
# Morgen
* Zugriff auf die Kamera in p5.js
* das Pixel Array
* Extended: Arbeit mit ml5.js

## Tutorial Kamera
Mit p5.js könnt ihr sehr einfach auf die Kamera zugreifen. 
```js
// tutorial
// https://www.youtube.com/watch?v=rNqaw8LT2ZU
let capture; // variable für kamera

function setup() {
    createCanvas(640, 480);
    pixelDensity(1);
    background(100);

    capture = createCapture(VIDEO); // https://p5js.org/reference/#/p5/createCapture
    capture.size(640, 480);
    capture.hide();
}

function draw() {
    capimg = capture.get(); // videostream in ein aktuelles Einzelbild kopieren
    image(capimg, 0, 0, width, height); //aktuelles Einzelbild darstellen
}
```
Bild per Klick speichern, Daten in JSON schreiben <br/><br/>


Der Code oben stellt euch den Videostream 1:1 dar. <br/>
Ihr könnt aber auf jeden einzelnen Pixel zugreifen und den verändern. <br/>
Informationen zum Pixel Array: https://docs.google.com/presentation/d/104VbNZyDklRJWsJmG86VUrvtpTb2S4PbhuwkliPYxVI/edit#slide=id.p<br/>
Pro Pixel gibt es vier Einträge im Array: https://docs.google.com/presentation/d/104VbNZyDklRJWsJmG86VUrvtpTb2S4PbhuwkliPYxVI/edit#slide=id.g1175de9062b_0_80 <br/>
Der folgende Code berechnet für jeden Pixel die Helligkeit aus rot, grün, blau und schreibt den Helligkeitswert zurück ins Array. Folge ist ein Bild in Grauwerten.

```js
function draw() {
    capimg = capture.get(); // videostream kopieren
    

    if (capimg.width > 0) {
         capimg.loadPixels(); // alle pixel in das array capimg.pixels laden

         for (let i = 0; i < capimg.pixels.length; i += 4) { //mit 4 hochzählen, weil es zu jedem Pixel vier Angaben hat
             let r = capimg.pixels[i + 0];//rot
             let g = capimg.pixels[i + 1];//gruen
             let b = capimg.pixels[i + 2];//blau
             let a = capimg.pixels[i + 3];//alpha

             let bright = (r + g + b) / 3;//aus rgb grauwert berechnen

             capimg.pixels[i + 0] = bright; //rgb Kanäle je auf denselben Wert (Grauwert) setzen
             capimg.pixels[i + 1] = bright;
             capimg.pixels[i + 2] = bright;
         }
         capimg.updatePixels(); //neue werte zurück schreiben in capimg.pixels
         
     }

     image(capimg, 0, 0, width, height);
}
```
Mit der Möglichkeit, auf jeden Pixel zuzugreifen und pro Pixel die RGBA Werte einzeln zu manipulieren, könnt ihr eigene Filter erstellen. Bsp. Kanäle tauschen, umkehren, etc. 
Hier ein kleines Beispiel, das einen Schwarz-Weiss Filter baut. Die Pixel sind entweder voll schwarz (falls Helligkeit unter 100) oder voll weiss (falls Helligkeit über 99).
Probiert einen eigenen Filter zu bauen. 

```js
 if (bright < 100) {
                capimg.pixels[i + 0] = 0;
                capimg.pixels[i + 1] = 0;
                capimg.pixels[i + 2] = 0;
            } else {
                capimg.pixels[i + 0] = 255;
                capimg.pixels[i + 1] = 255;
                capimg.pixels[i + 2] = 255;
            }
```
Extended: <br/>
Daniel Shiffman zeigt hier, wie ihr ein Rasterbild baut. https://www.youtube.com/watch?v=m1G6WBvrOBE <br/>
Ihr lest eine verkleinerte Version des Kamerastreams ein (braucht weniger Speicher und Performance) und bläst dann diese Version in einzelnen Rasterpunkten auf. <br/>
Schaut das Video und versucht, das nachzubauen. <br/>
Erklärungen, wie x und y Position mit dem Schlüssel im Pixel Array zusammenhängen, hier: https://docs.google.com/presentation/d/104VbNZyDklRJWsJmG86VUrvtpTb2S4PbhuwkliPYxVI/edit#slide=id.g1175de9062b_0_35 <br/><br/>

Die Rasterpunkte könnten nun irgendetwas sein, auch Buchstaben, Icons, etc. <br/>
Entwirf deine Version. <br/><br/>



# Nachmittag 
Einblick in maschinelle Gesichtserkennung, wie funktioniert das? <br/>
Slides: https://docs.google.com/presentation/d/1Rqbl5wPsjxYDx1GeRNrJxsReSzqGmfIKhN7c9xB7mfU/edit#slide=id.g78047df553_0_770 <br/><br/>
<b>Ausprobieren:</b>
## Google Vision Online
https://cloud.google.com/vision/docs/drag-and-drop?hl=de

## Tutorial ml5.js 
https://ml5js.org/about <br/>
https://learn.ml5js.org/ <br/>
ml5.js ist inspiriert von p5.js. Die Bibliothek wird durch Codebeispiele, Tutorien und Beispieldatensätze unterstützt, wobei der Schwerpunkt auf ethischer Datenverarbeitung liegt. Voreingenommenheit in Daten, stereotype Schäden und verantwortungsvolles Crowdsourcing sind Teil der Dokumentation zur Datenerfassung und -nutzung. 

<b>Beispiel Face-Api: https://learn.ml5js.org/#/reference/face-api in Kombination mit p5.js</b><br/>
Neues Projekt erstellen: 
```
directory_name/
    - index.html
    - assets/
        - style.css
        - js/
            - scripts.js
```
Im index.html beide Libraries einbinden, im head, alternativ könnt ihr die Libraries auch lokal laden und so einbinden:
```html
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.0.0/p5.min.js"></script>
    <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
```
Im Body bevor er schliesst, script.js einbinden:
```html
<script src="assets/script.js"></script>
```
Im script.js diesen Code kopieren:<br/>
https://editor.p5js.org/ml5/sketches/FaceApi_Video_Landmarks <br/>

## Bias bei Emotionen, Alter, Gender 
ml5.js unterstützt die Erkennung von Emotionen, Alter und Gender nicht (bei der ursprünglichen library von tensorflow vorhanden), da die community diese Modelle als stark biased beurteilt. <br/>
Dennoch kann die Integration dieser Modelle zu Testzwecken oder für das Ausprobieren neuer Interaktionen interessant sein. Beispiel Screenshot auslösen, wenn die Person lacht. <br/>